some tags for blog posts:
vision, programming, education, lifestyle


Learning to leap over the pitfall of premature implemetation details.

duplicates vs reoccurrences
Not about the elements themselves, but their occurrences
what made me realize this is oac/2016/1/2
if wanted to implement as duplicates, could not be lazy...
unless I would break what I would expect from the function.
Made me realize duplicates was improper abstraction! Too specific! Premature implementation detail!
Why does it matter though?




Algebra: visualizing structure
exercises (boxes, colors)
AST
a 'rewriter' of any formula,
given some axioms, gives list of all versions.
somehow bind this, could grow infinitely.
somehow order results by favoritism, give some heuristics.





overcoming the imperative-declarative ambuiguity of English
= always imperative, start name with -> to 'cheat out' a declarative name





The rationale of Uncle Bob's "three lines per function" rule and the two uses of a name.
uses of a name:
- to summarize meaning
- to provide a context for an implementation

I came to realize the second use of a name by this example
<< see cfn/assets, bottom few functions >>

Uncle Bob's "three lines per function" rule supports understandability through brevity.
Minimal irrelevant details = maximal abstraction.
The abstraction is achieved by names.
However,
- These names need not be functions, but can be values also;
- These names need not be introduced outside function scope; let block can be fine.






Why programming is useful and why I love it so much; or: software is an implementation detail.

externalization

Bonus: I love Clojure so much because to me expressing myself in it feels most natural of all programming languages.





What's the benefit of simplicity?

problem -> perceived problem -> solution -> implementation -> test

An implementation is simple when it straightforwardly maps to the problem.

Keeping things simple will allow us realize if what we're doing is actually what we're supposed to be doing.

Being simple is about minimalism; unburden mind as much as possible to we can think of relevant things.




Optimizing code for storytelling and why I don't like space-dictated syntax such as Python's.

use spacing to make reader aware of things.

Juggle the (non) use of threading macro's to increase storytelling.






Why for most people 'real world' programming languages are bad tools to learn programming.
designed for productivity (are conventient) and performance (provide many options that are similar but different).
Thus they have much implicit and irregular behavior and have irregular syntax.







Analyzing clojure core functions with a clojure program.






A dream of declarative data transformations.
Meander
looked in syntax, quickly boggled...
Makes sense: higher level stuff, can express more... if you want all that expressivity 'first class', language needs to be bigger.
Same as chinese vs english.
Chinese has many characters, each representing a thing. English few characters, but can easily compose with knowing little.

Get the same feeling with meander; to makes clear there is a limit in how abstract/expressive a _general programming language_ can or should be.
Although the problem statement of Meander hit home immediately, for now I am content with keeping my toolkit mentally managable at the cost of expressivity.






Why I don't like the word 'coding' and why I don't like the 'coding' interviews I see on YouTube;
and: the difference and relations between computer science, coding, programming and software engineering
Comment on 'Google coding interview'.
"makes me want to give up coding".
He was asking CS questions, not coding questions!
Programming is the combination of computer science AND coding.
Need both: educate yourself!
coding is an implementation detail (see some other blog post)
Software engineering is programming and much more. About ethics, best practises and disciplines.






why a theoretical computer science education is very worthwhile for a software engineering job.

The advantage theory has over practise is that theory is less restricted. Don't have to wait for things to happen, don't have to physically/actually perform steps. Theory allows for focus and deliberate practise of a particular aspect. However, practise is vital (application must be trained as well. So what's a good ratio? Depends on the person; I would say at least 50% theory.

At work, people from university not taken seriously because they can't do anything.
In general: true.
At uni don't learn much practical stuff. Never touched a version control system. Never touched a terminal.
Spent years developing insights on stuff like time complexity, something which during my engineering job only rarely is relevant knowledge.
However, had the opportunity to spend years developing insights;
Engineering is what work is; you get the opportunity to learn on the job.
On an engineering job, don't get the oppornity; if you do, it's not often.
I learned a lot about engineering (functional programming, stratified design, clean code, clean architecture, the tools, the practises).

example: state machines; non-uni guy started building, spent days debugging something.
I took a look, after 30 minutes spotted a potential deadlock.
During meeting could rebuff a complaint about adding an empty thing to db for each other thing; that would be O(N+1) per thing instead of O(N); no biggie.






'Old school' vs. 'new school' functional programming; and: functional programming is a bad name.





Writing detailed explanations of my opinions; a programming exercise.

started with merge requests.
Made me wonder: stuff that's 'ugly'; are there 'universal rules' for beauty?
such as: narrow scope of data asap.
equal names equal semantics.





The act of writing any program is itself in the spirit of functional programming.
seperating plan from action
e.g. what needs to be drawn to drawing it.
Tellman's Always Be Composing; data more composable/maleable.
Normand: clearly distinguishing data, calculating, action
writing a program is exactly that!
seperating the plan from action allows compiler to do smart things, allows humans to reason about the plan without any action having to take place.





Musing on Religion
- ancient wisdow
- food advise
- sinterklaas, norse mythology
- birth of a new one
- dangers of implementation hiding solution hiding problem.
  - zuivel is duivels, but it's not necessarily dairy
  - in law, there is this thing where the rationale is documented...
  
  
  
  
The Blade Itself
- tool shapes the wielder
- programming same: language has path of least resistance
- natural language also. Preservation of languages = preservation of perspectives!
- caesar burned his boats... generalization: possibilities are tempting
- "willpower is for losers" on youtube.
- keuzestress
- lessons learned:
  - try new tools, they will shape your perspective on the world
  - safeguard our languages
  - find the right tool for the right job
  - simplify life by removing options





Musing on Communication
data vs information
general model of communication
... sender, signal, recipient, noise too high level already, need something more basic.





The Last Argument of Kings
- Virtuality vs physicality
  - echoes information vs data, see On Communication
- moet eigenlijk meer bij data vs informatie: andere realms, andere wetten. bv argumenten voor diefstal gelden niet voor informatie.
- both are domains of power; only physicality is inevitable.
- Respect / receptivity for either is cultural. Story of guy in prison; troublesome youths in netherlands
- Communication!!!!! if audience is not receptive of your produced data, change your data.
- 'Was u bestemmingsverkeer?'





The Name of the Wind. Or: Musing on Names
- theme in fantasy: power of names
  - name of the wind ; much understanding yields you the true name of something
  - lies of locke lamora ; true name of something yields control
  - maybe farseer?
  - can remember vaguely if you know the name of a creature, you control it. look this up.
- words are a summary of a vast bank of understanding
  - communicators, teachers, be aware of this! Refer to On Communication: always interpret your data roleplaying as your audience.
- naming is common theme in programming
  - talk about (maybe separate blog post) on renaming adventures in the assets ns of cfn service)
    - realization: names do not only summarize, but also provide context / set a mood / set expectations.
  
  
  
  
Musing on Education
- there are no silver bullets; always depends on the indivual. but: many individuals are similar.




Collecting perspectives.
- Rener Gracie said: like watching a tree: you 
  - reminds me of this project in visualization project by acquiring a 3d model of an object by visually (2d) scanning it from multiple angles
- comments on youtube: OMG you are great explainer, I finally understand.
  - noted that all sorts of videos.
  - partly because explanation depends on the person (refer to post on Educaiton)
    - perhaps partly because this video was the final angle / perspective needed to get the full picture
    
    
    
#vision #programming    
Programming for the general population
- rather: non-specialists
- why?
  - 'great independence & means of artistic self-expression'
  - my thesis: process many excel sheets...
  - even simple regex stuff: from phone records, get me all unique phone numbers.
  - or regexy stuff: in document, replace a group within a match with something else...
  - calculuate, simulate...
  - jobs: sales people need sql skills... 
    - not only are DSLs sometimes not present, sometimes general programming is useful (cut out image, find phone numbers...)
  - I see all the options because I am an expert...
  - rise of 'data science'
    - many acquitances who studied whatever have 'data scientist' as job title
    - rather: rise of much information that needs processing.
- stone tables & chisels -> parchment & ink -> post-it and pen
- for programming, currently we're in the parchment & ink phase
- what will our post-it and pen equivalent be?
- programming is very useful but don't need all this high grade stuff.
- even within professional software engineering; don't always need cloud hosting... just a server to run it.
- future of programming: there is a very stable, easy to use, accessible language for general use. Or at least, multiple.
- like writing: no, we don't need it. 100 years ago most people couldn't write.
  - it does improve our lives.
  - 'knowledge economy'; stay competittive!
  - even if globally we don't and you're a rando reading this: give yourself an edge, learn how to program.
- what do we need for this?
  - a common data format
  - ...
- what are some 'post-it+pen' equivalents for programming?
- dice rolling in risk
- monty hall
- phone numbers
- conclusion: programming benefits the general population but the tools are not suitable to be used by the general population.
both education wise (refer to blog post on why programming education is bad atm) and eventual usage. for eventual usage: takes long to learn, much effort to use
(deploy, especially).
- easily accessible, quick to start using
  - installed on every phone / computer by default
  - drag and drop
  - example: kosmos clojure graphical
- maybe two languages for gen pop: one is slightly more powerful
- tiers of literacy: speech, writing, programming
  - increasingly: requires more resources / infrastructure, slowness, power, applicability
  - in the past: writing not worth the investment to learn, cost of resources greater than gain.
    - nowadays, paper and pens everywhere.
    - within a tier, still different levels: professional writers use slow, maintenance heavy tools (computers, LaTeX).
    - even computers are commodity nowadays. Was not the case with typewriters even, 40 years ago.
   - now we write (and read) a lot. Interesting; we program little, but do consume programs ('read') them all the flipping time. Perhaps as much
  - reading, especially writing done much more the more academic you get. Same trend for programming.
    - So perhaps that's the conclusion: learning to program only worthwhile at a certain level. See that: any research involves processing much data. Must automate to stay competitive. vwo = programming mandatory.





about programming on vwo: would be a base skill, next to language, mathematics, learning, teamwork.
programming sits is a corner similar to mathematics. About that... many maths students have trouble seeing the structure in an equation, find it difficult to recognize the patterns that allows them to use axioms. Perhaps a new notation, similar to my approach to seeing structure in instructions? More of a tree structure, semi graphical. What would that look like?
pretty much an AST. Perhaps same issue: mathematical notation is too convenient for some students; they first need an equally powerful but less convenient yet more understandable language / notation.



Schools: Reloaded

more on the basic subjects... language already specialized. Communication more general.
Also, English really that important, billingual education only full measure. How to balance though with preserving our native language and thus our native way of thinking / perspective?
Ground layer:
  - internal:
    - Discipline / willpower (forming and learning how to form good habits)
    - self awareness (who are you, what do you want, what makes you happy
    - critical thinking, realism, humility, confidence, acceptance
    - self care: healthy mind, body and soul.
      - more time between periods of sitting and paying attention, to move and unwind. 50, 25. Mind learns in rest. 25 minutes are not wasted.
        - what would schedule look like? Let's say start at 8.00, 9.15, 10.30, 11.45, 13.00, 14.15, 15.30 ends at 16.45. That's 7 slots a day! Let's say only in later years (15+?) you can be assigned the last slot. 
    - learning / deliberate practise!
  - external:
    - Communication
    - teamwork (including social stuff like understanding, respect, roles, responsibility, leadership)
  - Some activities touch multiple of the above, for instance broadening the mind by collecting perspectives:
    - self development, it gives you a mirror to reflect with. Perhaps this is something I agree with?
    - understanding and respect towards others.
  - Note that all of the above could also be applied and would be of much value 3000 years ago.

Already more specific: Languages: Native language (e.g. Dutch), General language (English), Mathematics, programming (for future academic-likes).
Although you might not like it, good to have a broad frame of reference. No need to become expert in many subjects, but to know a little gives you more worldly nodes to connect to.

General though here is that Dutch people get much more done in the same time. Flexibility, 'meedenken', being reasonable.






What if we would all learn sign language?






The bad thing about literature is that it's written by authors.
- videos by videomakers
- interesting what happens when a new person with fresh perspective has a go
- that movie about time travel
- programming cell simulation with my brother










Benefits of Digging Deep
- benefits of reflection / retrospectives
- refer to post on spirituality
- programming: ugly code: why is it ugly? can we come to a deeper understanding, formulate some rules (of thumb).
  - by making it formalized rules, we reap the befenits of externalizing (refer to post)
  - narrow scope of data
  - one meaning per word
  
  
  
  
  
Similarities between Generative algorithms and tdd.
Original thought: can't work with code because any small change to code will break it.
Then saw 'an hour with uncle bob' where he does TDD prime factorization.
He said: now, at some point I did a change; it worked, and don't know why.
same feeling / effect as generative algorithms!
So my original thought can be 'fixed' by saying the steps should be larger.
Difference with generative algorithms is that currently we can't automate these steps yet, require too much human intelligence.
If we ever get AI to a point where they can do TDD, we are a step closer to automating software.
Interesting(?)





separation of entity and identity





design of this blog:
initially, important to be free
easy to update
but, want comments!
writing is great (ref: externalization) but feedback / responses take it to the next level.
github pages easy to use, but is static...
comments as a microservice!
benefits:
content stays easy to use, fast & stable (github hosted)
comments are 'dynamic content'; requires more smart stuff to happen (e.g. database).

don't want spam and also gives some humanity to the messages... so, authentication.
ux wise, threshold should be low (please comment, I want to know your thoughts!).
and don't want to implement account management... OAuth!
GitHub, Google, Reddit, Twitter.

functional requirements: user can claim an authenticated identity, use this identity to place a comment.
comments are sorted in time.
can edit and delete comment after creation. => need to store identity and identity authenticator.
can 'reply' to a comment, breaking the relation between order of appearance and time of creation.
this throws a small wrench in deleting comments... solution: soft delete (remove all personal data and content from comment, just keep it as a placeholder: "there used to be a comment here").

Initial idea was to only persist user information in the form of identity and identity authenticator;
front end can fetch more details (github.com/user/bla, reddit.com/user/bla).
However, when implementing google, found out you can't do this; can only fetch personal info if you are authorized.
So, will have to store name and profile picture as well.
Perhaps nicer, even... ref: seperation entity identity.
When you posted under a previous name with a previous picture, that was under a certain identity. Identity is more htan just a username or identifying number in some authorizer's database. The data that represents your identity for the authenticator is not the identity you posted with: that identity is decided also by name and picture.
So, this issue gave me a new perspective and I like it.

I want a thin backend, but security wise, anything can be posted...
who posted commented, to what article, what was the comment.
who (name) posted: anything can be sent to backend... so instead of doing that, backend will use access token to fetch details.
flow: front end creates request token, send its to backend, backend creates access token (by also providing the client secret; which fits nicely with trying to keep the secret a secret; can't create access token in front end), but back end DOES NOT CARE ABOUT SESSION MANAGEMENT.
instead, backend passes access token back to front end. Front end can at some later point pass any access token to back end, which back end will use to fetch identity details.
My initial thought was: security leak. And sure; backend signs a token with client secret (tied to my personal accounts, yikes), which it then exposes to the big bad world. Anyone can now use that access token with my personal signature on it to do whatever.
However, that's where token scope comes in handy. Before user grants permission, it is known what the power of the access token will be: what data it will have access to and which actions it can perform.
The scope for my case is very minimal; just read some data. I can accept that anyone else can also read that data.
But can I accept that?
User gave ME permission to read, they trust ME. I don't want to break that trust by then virtually giving that permission to everyone in the world.

Great example again of ref: externaliation!

So then what? Keep access token hidden in back end. But, need some link between front end and back end, so that front end can tell me which token to use.
That would mean any baddy also has access to that link; baddies can still use (by proxy) that access token. However, scope of use of that access token is now limited. Intead of doing whatever the scope granted by the authorizer allows, scope is now narrowed to whatever my backend offers in terms of functionality:
posting a comment to an article on my website. Although the scope of the access token is now even narrower, still some information bleeds through: the name and profile picture. (because backend uses access token to fetch these, which were otherwise inaccessible, maybe).
So the question is: would the access token be able to retrieve any data that is otherwise not publically accessible?
For GitHub and Reddit the answers would be: no.
However, for Google it's yes. Although name and pic bleed through, id and locale (are part of the data accessible by token but) are not bled trough.
Who cares? I care. Trust is a precious gift. Besides, in the future (although I do not expect this, but who knows), more data might be contained in that authorized-locked request to Google. So, I must.
On the other hand... access token will only live in their browser and connections are secure (https). People also, at some point, have their bank account password inside their browser (when you type it in). So, no proxy token! just pass back the access token to FE, at some point expect an access token to use to sign the comment with.

Then maybe move the flow to backend entirely? Front end will have perspective: a few buttons with which to log in; when pressed, post to backend. Backend starts login flow. But how do I communicate back to front end that flow is complete...? FE waiting on response could time out, not nice. FE is static... Sockets way too complicated... Requesting the request token is fine on the front end; callback url will be front end, so no need to wait on anything.
So at some point FE receives a request token. Sends this to BE, who will convert it to access token. BE send back a proxy for the access token; proxy token? Can then as well send name, so user sees the guise they will be commenting under. So what about session management? BE knows when token will expire. Can set a timeout for that to remove token. Not going to do refresh flow for now; just log in again. Perhaps even nicer to have a max lifetime on server as well, in case auth token is very long; let's say 2 hours. So set timeout (min max-lifetime token-lifetime) to remove mapping proxy token -> access token; if front end tries to do anything with proxy token after that, they will get a response like 'unrecognized proxy token' and it can inform the user they need to log in again.

nice subdomain: comment.jeroenvanwijgerden.me
deployed on heroku (free!, might have start up time, but doesnt matter because not the comments but the articles are the main feature of website).


Comments thing doesn't have access to any db contaning articles. Besides, articles aren't even stored in a db (static website).
So, generate a uuid for each of your articles and don't change it over commits.
Mallory's could send fake comments to backend; ones that do not belong to an actually existing article.
That fills up the db...
but won't pollute visible articles anymore than the mallory's just deliberately spamming on a 

On the topic of spam: let's add a timeout per user to post. Should be so that humans are discouraged to spam, bots can't spam, behaving users are not punished.
I think 1 minute is reasonable... if you make a mistake, you can always edit without a timeout. Let's make that configurable.

Also configurable: with oauth providers. They use different ways (some bearer token, some client_secret param...), so come up with a clever enough config scheme.

To start using this comment service:
get client ids/secrets for any oauth authorizer you want (GitHub, Google, Reddit, Twitter, ...).
clone/form the repo.
deploy with env vars set, attach a db.

in your FE:
give each article a uuid
include a login thing
send requests to your backend however you like
store access token and username somewhere.
